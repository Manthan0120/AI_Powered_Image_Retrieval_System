# AI-Powered Image Retrieval System

[![Streamlit App](https://img.shields.io/badge/Streamlit-App-brightgreen)](https://streamlit.io/)

An image similarity search system trained on the **Caltech101 dataset** using **ResNet50** with **triplet loss**. Extracts deep embeddings, builds **FAISS** index for fast similarity search, and provides an interactive **Streamlit** web interface for querying visually similar images.

## ðŸ“ Project Structure

```
caltech101/
â”œâ”€â”€ data/                    # Features, FAISS index (faiss_index.bin, features_path.json)
â”œâ”€â”€ weights/                 # Trained model weights (model.pth)
â”œâ”€â”€ src/                     # Model architecture
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ model.py            # ResNet50 transfer learning with triplet loss
â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py       # Dataset loading & triplet dataset
â”‚   â”œâ”€â”€ image_utils.py      # Image preprocessing
â”‚   â”œâ”€â”€ faiss_utils.py      # FAISS indexing utilities
â”‚   â””â”€â”€ precompute_features.py # Feature extraction script
â”œâ”€â”€ app.py                  # Streamlit web interface
â”œâ”€â”€ precompute.sh           # Feature extraction & indexing script
â””â”€â”€ README.md
```

## ðŸš€ Quick Start

### 1. Prerequisites
```bash
pip install torch torchvision streamlit faiss-cpu pillow matplotlib numpy
```

### 2. Train the Model
```bash
# Split dataset into train/val
python -c "from utils.data_utils import split_dataset; split_dataset('path/to/caltech101')"

# Train model (outputs weights/model.pth)
python -c "from src.model import ResNetTransferModel, train_model; from utils.data_utils import TripletDataset; # ... (training code)"
```

### 3. Generate FAISS Index
```bash
chmod +x precompute.sh
./precompute.sh
```
*This extracts features using trained model and builds FAISS index in `data/`*

### 4. Run Streamlit App
```bash
streamlit run app.py
```

## ðŸ› ï¸ Workflow

1. **Training**: ResNet50 with triplet loss learns to embed similar images close together
2. **Feature Extraction**: Precompute embeddings for all dataset images â†’ `data/features.npy`
3. **Indexing**: Build FAISS L2 index â†’ `data/faiss_index.bin`
4. **Querying**: Upload image â†’ extract embedding â†’ find nearest neighbors in FAISS index

## ðŸ” Key Features

- **Modular Architecture**: Clean separation of model, data, utils, and app
- **Efficient Search**: FAISS provides sub-linear similarity search
- **Interactive UI**: Streamlit app with upload and visual results
- **Production Ready**: Precompute pipeline with shell script

## ðŸ“Š Results

The system achieves fast retrieval of visually similar images using Euclidean distance on normalized embeddings (equivalent to cosine similarity).

## ðŸ“ Usage in App

1. Upload query image
2. View top-k retrieved images with distance scores
3. Compare visual similarity instantly

## ðŸ”§ Customization

- Adjust `top_k` in app for more/fewer results
- Modify image size in `display_results()` function
- Retrain model with different hyperparameters in `src/model.py`

## ðŸ“š Dependencies

```
torch>=2.0
torchvision>=0.15
streamlit>=1.28
faiss-cpu>=1.7
pillow>=10
matplotlib>=3.7
numpy>=1.24
```

## ðŸŽ“ Learning Objectives

This project demonstrates:
- Transfer learning with ResNet50
- Triplet loss for embedding learning
- FAISS for efficient similarity search
- Streamlit for ML app deployment
- Modular Python package structure

---

**Built for Caltech101 image retrieval challenge** ðŸš€
